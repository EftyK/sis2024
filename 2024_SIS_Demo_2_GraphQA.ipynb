{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Nv0FvC7kT3KR",
        "J-MZn6LV9qtB",
        "BV4UuEw5kxaV"
      ],
      "authorship_tag": "ABX9TyMJqku/KwBmn8iEciiiYtpC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Topics: Data Modelling and Search Models\n",
        "* Langsmith (for inspection and debugging)\n",
        "* Semantic model extraction (continued)\n",
        "* Graph QA using GraphCypherQAChain\n",
        "* Graph QA using Vector Indices"
      ],
      "metadata": {
        "id": "43I3IWmdbtN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1:  Langsmith"
      ],
      "metadata": {
        "id": "KsUHp7-VRbf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Documentation](https://docs.smith.langchain.com/)"
      ],
      "metadata": {
        "id": "Pbug8ocywoO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Website](https://www.langchain.com/langsmith)"
      ],
      "metadata": {
        "id": "hWn48jeBOlOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langsmith"
      ],
      "metadata": {
        "id": "YaMwdPwo6hVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32915be-98ed-406e-bbd6-93f564b3d7c9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m555.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "pTM4jeoO7J7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63363809-2fe8-4070-8777-278e728f7398"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"YourKey\""
      ],
      "metadata": {
        "id": "HA5Nm88y6ovr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "PgGWbFpq7fGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9902e25-16d5-4286-9102-e675298f9b62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"),\n",
        "    (\"user\", \"Question: {question}\\nContext: {context}\")\n",
        "])\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "output_parser = StrOutputParser() # https://www.restack.io/docs/langchain-knowledge-langchain-stroutputparser-guide\n",
        "\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "question = \"What are the place names and geopolitical entities mentioned in the context?\"\n",
        "context = \"Germany is a country in Europe and its capital is Berlin.\"\n",
        "chain.invoke({\"question\": question, \"context\": context})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vrjyoGMWSxFI",
        "outputId": "e3a0cd82-e78d-4875-f861-4ab2340dcc67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Place names: Germany, Europe, Berlin\\nGeopolitical entities: Germany'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2: Semantic Model Extraction"
      ],
      "metadata": {
        "id": "Nv0FvC7kT3KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-community langchain-openai langchain_experimental neo4j"
      ],
      "metadata": {
        "id": "z2yaxk974TjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bfca12-050e-47c6-f9c4-06345e4513ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.graphs import Neo4jGraph\n",
        "\n",
        "url = \"YourUrl\"\n",
        "username = \"neo4j\"\n",
        "password = \"YourPassword\"\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password\n",
        ")"
      ],
      "metadata": {
        "id": "DwOmWv9h4ZAN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "Kc7B0jrCvAZO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From wikipedia: https://en.wikipedia.org/wiki/M%C3%BCnster\n",
        "example_text = \"\"\"\n",
        "Münster is an independent city (Kreisfreie Stadt)\n",
        "in North Rhine-Westphalia, Germany. It is in the northern part of the state and is considered to\n",
        " be the cultural centre of the Westphalia region. It is also a state district capital. Münster was the\n",
        "  location of the Anabaptist rebellion during the Protestant Reformation and the site of the signing of the\n",
        "   Treaty of Westphalia ending the Thirty Years' War in 1648. Today, it is known as the bicycle capital of Germany.\n",
        "Münster gained the status of a Großstadt (major city) with more than 100,000 inhabitants in 1915.[4]\n",
        " As of 2014, there are 300,000[5] people living in the city, with about 61,500 students,[6]\n",
        " only some of whom are recorded in the official population statistics as having their primary residence in Münster.\n",
        " Münster is a part of the international Euregio region with more than 1,000,000 inhabitants (Enschede, Hengelo, Gronau, Osnabrück).\n",
        " Companies offering jobs in Münster include the Institute for Geoinformatics at the University of Münster,\n",
        " the Münster University of Applied Sciences, Reedu GmbH, con terra, the Deutsche Bank, IKEA, LIDL, REWE, ALDI and BASF Coatings.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HZePyU65vKrD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-turbo\") # https://platform.openai.com/docs/models\n",
        "\n",
        "llm_transformer = LLMGraphTransformer(llm=llm) # documentation, see https://python.langchain.com/docs/how_to/graph_constructing/"
      ],
      "metadata": {
        "id": "nO9j2tbdvPIc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [Document(page_content=example_text)]\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
        "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
        "print(f\"Relationships:{graph_documents[0].relationships}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYnlGBY8vTVD",
        "outputId": "b04410a5-41cc-4969-ab43-9ce3856dd6f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes:[Node(id='Münster', type='City', properties={}), Node(id='North Rhine-Westphalia', type='State', properties={}), Node(id='Germany', type='Country', properties={}), Node(id='Westphalia', type='Region', properties={}), Node(id='Anabaptist Rebellion', type='Event', properties={}), Node(id='Protestant Reformation', type='Event', properties={}), Node(id='Treaty Of Westphalia', type='Event', properties={}), Node(id=\"Thirty Years' War\", type='Event', properties={}), Node(id='Euregio', type='Region', properties={}), Node(id='Institute For Geoinformatics', type='Organization', properties={}), Node(id='University Of Münster', type='University', properties={}), Node(id='Münster University Of Applied Sciences', type='University', properties={}), Node(id='Reedu Gmbh', type='Company', properties={}), Node(id='Con Terra', type='Company', properties={}), Node(id='Deutsche Bank', type='Company', properties={}), Node(id='Ikea', type='Company', properties={}), Node(id='Lidl', type='Company', properties={}), Node(id='Rewe', type='Company', properties={}), Node(id='Aldi', type='Company', properties={}), Node(id='Basf Coatings', type='Company', properties={})]\n",
            "Relationships:[Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='North Rhine-Westphalia', type='State', properties={}), type='LOCATED_IN', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Westphalia', type='Region', properties={}), type='CULTURAL_CENTRE', properties={}), Relationship(source=Node(id='Anabaptist Rebellion', type='Event', properties={}), target=Node(id='Münster', type='City', properties={}), type='LOCATION', properties={}), Relationship(source=Node(id='Treaty Of Westphalia', type='Event', properties={}), target=Node(id='Münster', type='City', properties={}), type='SIGNING_LOCATION', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Germany', type='Country', properties={}), type='BICYCLE_CAPITAL', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Euregio', type='Region', properties={}), type='PART_OF', properties={}), Relationship(source=Node(id='Institute For Geoinformatics', type='Organization', properties={}), target=Node(id='University Of Münster', type='University', properties={}), type='PART_OF', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Institute For Geoinformatics', type='Organization', properties={}), type='EMPLOYER', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Münster University Of Applied Sciences', type='University', properties={}), type='EMPLOYER', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Reedu Gmbh', type='Company', properties={}), type='EMPLOYER', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Con Terra', type='Company', properties={}), type='EMPLOYER', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Deutsche Bank', type='Company', properties={}), type='EMPLOYER', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Ikea', type='Company', properties={}), type='EMPLOYER', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Lidl', type='Company', properties={}), type='EMPLOYER', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Rewe', type='Company', properties={}), type='EMPLOYER', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Aldi', type='Company', properties={}), type='EMPLOYER', properties={}), Relationship(source=Node(id='Münster', type='City', properties={}), target=Node(id='Basf Coatings', type='Company', properties={}), type='EMPLOYER', properties={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.add_graph_documents(graph_documents)"
      ],
      "metadata": {
        "id": "8dHnhXk84n9h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3: Graph QA using GraphCypherQAChain"
      ],
      "metadata": {
        "id": "J-MZn6LV9qtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  --quiet langchain langchain-openai langchain-community neo4j"
      ],
      "metadata": {
        "id": "kaQFfQ539seN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.graphs import Neo4jGraph\n",
        "\n",
        "url = \"YourUrl\"\n",
        "username = \"neo4j\"\n",
        "password = \"YourPassword\"\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password\n",
        ")"
      ],
      "metadata": {
        "id": "GolFRbIT98CE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "oO3-1C_9iV47"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    graph=graph,\n",
        "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-4o-mini\"), # gpt-4o-mini\tgpt-3.5-turbo\n",
        "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\"),\n",
        "    verbose=True,\n",
        "    allow_dangerous_requests=True\n",
        ")"
      ],
      "metadata": {
        "id": "ORmHBZE89_9z"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_1 = \"What is the population of Hessen?\"\n",
        "question_2 = \"What is the geometry of Rheinland-Pfalz?\"\n",
        "question_3 = \"What are the areas of Hessen and Niedersachen. Is the area of Hessen bigger than the area of Niedersachsen\"\n",
        "question_4 = \"Is Düsseldorf the state capital of Nordrhein-Westfalen\"\n",
        "\n",
        "chain.invoke(question_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MlmganG9yec",
        "outputId": "c8faf5af-0a4a-4117-b9ad-89f24f5e273a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mcypher\n",
            "MATCH (s:State {name: 'Nordrhein-Westfalen'}) \n",
            "WHERE s.state_capital = 'Düsseldorf' \n",
            "RETURN s\n",
            "\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'s': {'area': 34110.26, 'name': 'Nordrhein-Westfalen', 'state_capital': 'Düsseldorf', 'population': 18139116}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Is Düsseldorf the state capital of Nordrhein-Westfalen',\n",
              " 'result': 'Yes, Düsseldorf is the state capital of Nordrhein-Westfalen.'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4: GraphQA using Vector Indices"
      ],
      "metadata": {
        "id": "fva46S3Zb8Rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing"
      ],
      "metadata": {
        "id": "rivtxf2dkuLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai wikipedia tiktoken neo4j langchain_openai langchain_community --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWZcQcLRlMPb",
        "outputId": "be55d0fd-f97f-4c91-a2f7-08fec169ecea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://neo4j.com/developer-blog/knowledge-graph-rag-application/\n",
        "# https://github.com/tomasonjo/blogs/blob/master/llm/devops_rag.ipynb\n",
        "from langchain.graphs import Neo4jGraph\n",
        "\n",
        "url = \"YourUrl\"\n",
        "username = \"neo4j\"\n",
        "password = \"YourPassword\""
      ],
      "metadata": {
        "id": "sb4QYjYElRAq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "afOIDKPImj_V"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HlWANUOz0C6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the index\n",
        "\n",
        "import os\n",
        "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    OpenAIEmbeddings(),\n",
        "    url=url,\n",
        "    username=username,\n",
        "    password=password,\n",
        "    index_name='index_for_state',\n",
        "    node_label=\"State\",\n",
        "    text_node_properties= ['name', 'population', 'state_capital', 'area'], #['name', 'description', 'status'], #['name', 'state_capital', 'url'],\n",
        "    embedding_node_property='embedding',\n",
        ")"
      ],
      "metadata": {
        "id": "jbWa90lejoVi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see the index just created\n",
        "vector_index.query(\n",
        "    \"\"\"SHOW INDEXES\n",
        "       YIELD name, type, labelsOrTypes, properties, options\n",
        "       WHERE type = 'VECTOR'\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5WQc6WAm2-M",
        "outputId": "631284c9-4ce1-4b98-b153-7a8480af5982"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'index_for_state',\n",
              "  'type': 'VECTOR',\n",
              "  'labelsOrTypes': ['State'],\n",
              "  'properties': ['embedding'],\n",
              "  'options': {'indexProvider': 'vector-2.0',\n",
              "   'indexConfig': {'vector.hnsw.m': 16,\n",
              "    'vector.hnsw.ef_construction': 100,\n",
              "    'vector.dimensions': 1536,\n",
              "    'vector.similarity_function': 'COSINE',\n",
              "    'vector.quantization.enabled': True}}}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval"
      ],
      "metadata": {
        "id": "QTBffq0fkvzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question1 = \"How many states in the database?\"\n",
        "question2 = \"How many geometries in the the database?\"\n",
        "question3 = \"What is the population of Hessen?\"\n",
        "question4 = \"What is the area of Hessen?\"\n",
        "question5 = \"What is the capital of Hessen?\"\n",
        "question6 = \"What is the geometry of Hessen?\"\n",
        "question7 = \"What are the geometries of Hessen and Niedersachsen?\"\n",
        "question8 = \"What is the url of the geometry of Hessen?\""
      ],
      "metadata": {
        "id": "H-SFqvF3lw8B"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = vector_index.similarity_search(question3)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUt4v84Tl0Ub",
        "outputId": "ed652ba9-1131-463a-a46d-b277ea320e16"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='\\nname: Hessen\\npopulation: 6391360\\nstate_capital: Wiesbaden\\narea: 21114.94'),\n",
              " Document(metadata={}, page_content='\\nname: Niedersachsen\\npopulation: 8140242\\nstate_capital: Hannover\\narea: 47709.82'),\n",
              " Document(metadata={}, page_content='\\nname: Nordrhein-Westfalen\\npopulation: 18139116\\nstate_capital: Düsseldorf\\narea: 34110.26'),\n",
              " Document(metadata={}, page_content='\\nname: Rheinland-Pfalz\\npopulation: 4159150\\nstate_capital: Mainz\\narea: 19854.21')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_with_score = vector_index.similarity_search_with_score(question3)\n",
        "response_with_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI3bBGOSl39j",
        "outputId": "baf88a3f-fcc6-4707-85be-b377350fbe50"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(metadata={}, page_content='\\nname: Hessen\\npopulation: 6391360\\nstate_capital: Wiesbaden\\narea: 21114.94'),\n",
              "  0.94384765625),\n",
              " (Document(metadata={}, page_content='\\nname: Niedersachsen\\npopulation: 8140242\\nstate_capital: Hannover\\narea: 47709.82'),\n",
              "  0.92498779296875),\n",
              " (Document(metadata={}, page_content='\\nname: Nordrhein-Westfalen\\npopulation: 18139116\\nstate_capital: Düsseldorf\\narea: 34110.26'),\n",
              "  0.9194488525390625),\n",
              " (Document(metadata={}, page_content='\\nname: Rheinland-Pfalz\\npopulation: 4159150\\nstate_capital: Mainz\\narea: 19854.21'),\n",
              "  0.917633056640625)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation: Example 1"
      ],
      "metadata": {
        "id": "BV4UuEw5kxaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using documents as context\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "numPBbYwnWfr",
        "outputId": "15735836-3ab8-4b65-b72a-c3946c085e3e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "75euLZagnfn5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "PPOxD3ICnlFr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = response\n",
        "\n",
        "chain.invoke({\"context\": docs, \"question\": question3})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "epdnd0jinoEP",
        "outputId": "e4724d29-47b5-42cd-dfe2-6e20d80d4725"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The population of Hessen is 6,391,360.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation: Example 2"
      ],
      "metadata": {
        "id": "CPhwJ-NsocNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a retriever as context\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "retriever = vector_index.as_retriever() # search_kwargs={\"k\": 1}\n",
        "\n",
        "graph_chain = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "                | prompt\n",
        "                | llm\n",
        "                | StrOutputParser()\n",
        "                )\n",
        "\n",
        "graph_chain.invoke(question3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wMYQYPtOoakL",
        "outputId": "3b8c2b1f-bdff-44c3-d3d7-7f4c2591fc14"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The population of Hessen is 6,391,360.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation: Example 3"
      ],
      "metadata": {
        "id": "tjYmkHlxtC9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a custom retriever as a context and post-processing of the answer\n",
        "# https://python.langchain.com/docs/how_to/custom_retriever/\n",
        "from typing import List\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "\n",
        "class CustomRetriever(BaseRetriever):\n",
        "    \"\"\" Custom retriever to return the scores of the documents as well.\n",
        "        Then the scores are passed into an custom ranking function to include the spatial similarity\n",
        "        between the query and the document.\n",
        "    \"\"\"\n",
        "\n",
        "    vector_index: Neo4jVector\n",
        "\n",
        "    def _get_relevant_documents(\n",
        "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
        "    ) -> List[Document]:\n",
        "        \"\"\"Sync implementations for retriever.\"\"\"\n",
        "\n",
        "        docs, scores = zip(*self.vector_index.similarity_search_with_score(query))\n",
        "        for doc, score in zip(docs, scores):\n",
        "             print(\"***\", doc)\n",
        "             #new_score = updated_score(score, query, doc)\n",
        "             doc.page_content = doc.page_content\n",
        "             doc.metadata[\"score\"] = score\n",
        "        return docs\n",
        "\n",
        "def update_scores(docs):\n",
        "\n",
        "    for doc in docs:\n",
        "       new_score = doc.metadata[\"score\"] * 10\n",
        "       doc.page_content = doc.page_content+ \"\\nScore: \" + str(new_score)\n",
        "       doc.metadata[\"score\"] = new_score\n",
        "    return docs"
      ],
      "metadata": {
        "id": "9tdhFRMxvgMM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "retriever_r = CustomRetriever(vector_index=vector_index)\n",
        "\n",
        "graph_chain = ({\"context\": retriever_r | update_scores, \"question\": RunnablePassthrough()}\n",
        "                | prompt\n",
        "                | llm\n",
        "                | StrOutputParser()\n",
        "                )\n",
        "\n",
        "graph_chain.invoke(question6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "fQqodttVtH5-",
        "outputId": "90fdda76-a330-4d5f-fbaf-4bbe771a418a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** page_content='\n",
            "name: Hessen\n",
            "population: 6391360\n",
            "state_capital: Wiesbaden\n",
            "area: 21114.94'\n",
            "*** page_content='\n",
            "name: Niedersachsen\n",
            "population: 8140242\n",
            "state_capital: Hannover\n",
            "area: 47709.82'\n",
            "*** page_content='\n",
            "name: Nordrhein-Westfalen\n",
            "population: 18139116\n",
            "state_capital: Düsseldorf\n",
            "area: 34110.26'\n",
            "*** page_content='\n",
            "name: Rheinland-Pfalz\n",
            "population: 4159150\n",
            "state_capital: Mainz\n",
            "area: 19854.21'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The geometry of Hessen is 21114.94.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cypher Queries"
      ],
      "metadata": {
        "id": "yQVWvsmwkq6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will not dive deep into the cypher syntax during the course. The following queries should be enough for the interaction with the neo4j database. You can also check the [documentation](https://neo4j.com/docs/cypher-cheat-sheet/5/aura-dbe/auradb-free), if you happen to need more."
      ],
      "metadata": {
        "id": "yvNXJS_B04j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete every node and edge\n",
        "MATCH(n)\n",
        "DETACH DELETE (n)\n",
        "\n",
        "# create nodes and edges\n",
        "follow the structure shown at https://github.com/aurioldegbelo/sis2024/blob/main/vector_data/data.cypher\n",
        "\n",
        "# visualize the model of the graph database\n",
        "CALL apoc.meta.graph()"
      ],
      "metadata": {
        "id": "POLTOnQ2j9Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project work"
      ],
      "metadata": {
        "id": "rzTwwHpcyOwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Exercice 01: clarify what your search target is\n",
        "\n",
        "* Exercice 02: elaborate on your data model (what are entities and relationships)\n",
        "\n",
        "* Exercice 03: create a neo4j account and a database instance\n",
        "\n",
        "* Exercice 04: create an example of cypher query (CREATE) for your data (just a few instances), upload it to the database to see if it works\n",
        "\n",
        "* Exercice 05: write a script to generate a CREATE query (it converts from your original format [csv, tsv, json, ...]) to a cypher template\n"
      ],
      "metadata": {
        "id": "63kwd8YDyuDb"
      }
    }
  ]
}