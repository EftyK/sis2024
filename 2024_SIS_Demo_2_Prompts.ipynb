{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvuscDQRKA2Fj0nA1cOUJP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Topics: Data Modelling and Search Models\n",
        "* Expansion via multi-query generation\n",
        "* Task decomposition\n"
      ],
      "metadata": {
        "id": "f-f_Xm04pxpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "qIYgAUmRqYae"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai"
      ],
      "metadata": {
        "id": "9EqIHkDgqa8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expansion (Multi-Query)"
      ],
      "metadata": {
        "id": "FizpL4nAqGmf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukt5Sk1IpkdV",
        "outputId": "7012b72d-5f3a-4a56-addc-480252c95cb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. Can you tell me the capital city of Germany?',\n",
              " '2. Which city serves as the capital of Germany?',\n",
              " '3. What is the official capital of Germany?',\n",
              " '4. Where is the governmental center of Germany located?',\n",
              " '5. Do you know the primary city that functions as the capital of Germany?']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Adapted from https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "\n",
        "# Multi Query: Different Perspectives\n",
        "template = \"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "different versions of the given user question to retrieve relevant documents from a vector\n",
        "database. By generating multiple perspectives on the user question, your goal is to help\n",
        "the user overcome some of the limitations of the distance-based similarity search.\n",
        "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
        "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "generate_queries = (\n",
        "    prompt_perspectives\n",
        "    | llm\n",
        "    | output_parser\n",
        "    | (lambda x: x.split(\"\\n\"))\n",
        ")\n",
        "generate_queries.invoke({\"question\": \"What is the capital of Germany?\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Another example of template/prompt for multi-query generation\n",
        "template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
        "Generate multiple search queries related to: {question} \\n\n",
        "Output (4 queries):\"\"\"\n",
        "prompt_rag_fusion = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "generate_queries = (\n",
        "    prompt_rag_fusion\n",
        "    | llm\n",
        "    | output_parser\n",
        "    | (lambda x: x.split(\"\\n\"))\n",
        ")\n",
        "\n",
        "generate_queries.invoke({\"question\": \"What is the geometry of Hessen?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBXYEEDcr5Fc",
        "outputId": "bd86d8f4-cce7-4a01-e730-4a0bd4acb19d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. What are the geographical features of Hessen?',\n",
              " '2. How is the land area of Hessen distributed?',\n",
              " '3. What are the boundaries of Hessen?',\n",
              " '4. What is the topography of Hessen like?']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decomposition"
      ],
      "metadata": {
        "id": "0pqo50czqIAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Decomposition\n",
        "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
        "The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
        "Generate multiple search queries related to: {question} \\n\n",
        "Output (3 queries):\"\"\"\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "prompt_for_decomposition = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "decompose_problem = ( prompt_for_decomposition | llm | output_parser | (lambda x: x.split(\"\\n\")))\n",
        "\n",
        "question1 = \"What is the capital of Germany?\"\n",
        "question2 = \"Which cities are north of Germany?\"\n",
        "question3 = \"What is the geometry of Germany?\"\n",
        "question4 = \"What is the population of Germany?\"\n",
        "question5 = \"What are hotels near the central train station in MÃ¼nster, Germany?\"\n",
        "\n",
        "#decompose_problem.invoke({\"question\": question1})\n",
        "#decompose_problem.invoke({\"question\": question2})\n",
        "decompose_problem.invoke({\"question\": question4})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZMYO-zntsmj",
        "outputId": "391999a8-3d2f-4862-ff91-831c9bdacff2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. What is the current population of Germany in 2021?',\n",
              " '2. How has the population of Germany changed over the past decade?',\n",
              " '3. What are the factors influencing the population growth or decline in Germany?']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}